{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cbe690c",
   "metadata": {},
   "source": [
    "# ASS_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc86b6",
   "metadata": {},
   "source": [
    "# . Implement Gradient Boost Classifier Model on Income Evaluation Data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef00b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2461241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load your dataset\n",
    "# Replace 'your_dataset.csv' with your file path\n",
    "data = pd.read_csv('income_evaluation.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass   fnlwgt   education   education-num  \\\n",
      "0   39          State-gov    77516   Bachelors              13   \n",
      "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
      "2   38            Private   215646     HS-grad               9   \n",
      "3   53            Private   234721        11th               7   \n",
      "4   28            Private   338409   Bachelors              13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "    capital-gain   capital-loss   hours-per-week  native-country  income  \n",
      "0           2174              0               40   United-States   <=50K  \n",
      "1              0              0               13   United-States   <=50K  \n",
      "2              0              0               40   United-States   <=50K  \n",
      "3              0              0               40   United-States   <=50K  \n",
      "4              0              0               40            Cuba   <=50K  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              32561 non-null  int64 \n",
      " 1    workclass       32561 non-null  object\n",
      " 2    fnlwgt          32561 non-null  int64 \n",
      " 3    education       32561 non-null  object\n",
      " 4    education-num   32561 non-null  int64 \n",
      " 5    marital-status  32561 non-null  object\n",
      " 6    occupation      32561 non-null  object\n",
      " 7    relationship    32561 non-null  object\n",
      " 8    race            32561 non-null  object\n",
      " 9    sex             32561 non-null  object\n",
      " 10   capital-gain    32561 non-null  int64 \n",
      " 11   capital-loss    32561 non-null  int64 \n",
      " 12   hours-per-week  32561 non-null  int64 \n",
      " 13   native-country  32561 non-null  object\n",
      " 14   income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "                age        fnlwgt   education-num   capital-gain  \\\n",
      "count  32561.000000  3.256100e+04    32561.000000   32561.000000   \n",
      "mean      38.581647  1.897784e+05       10.080679    1077.648844   \n",
      "std       13.640433  1.055500e+05        2.572720    7385.292085   \n",
      "min       17.000000  1.228500e+04        1.000000       0.000000   \n",
      "25%       28.000000  1.178270e+05        9.000000       0.000000   \n",
      "50%       37.000000  1.783560e+05       10.000000       0.000000   \n",
      "75%       48.000000  2.370510e+05       12.000000       0.000000   \n",
      "max       90.000000  1.484705e+06       16.000000   99999.000000   \n",
      "\n",
      "        capital-loss   hours-per-week  \n",
      "count   32561.000000     32561.000000  \n",
      "mean       87.303830        40.437456  \n",
      "std       402.960219        12.347429  \n",
      "min         0.000000         1.000000  \n",
      "25%         0.000000        40.000000  \n",
      "50%         0.000000        40.000000  \n",
      "75%         0.000000        45.000000  \n",
      "max      4356.000000        99.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Understand the data\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005b6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Preprocess the data\n",
    "# Handle missing values if any\n",
    "data = data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de109e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numeric (if any)\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e597c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define features and target\n",
    "# Replace 'target_column' with the name of your target column\n",
    "X = data.drop(columns=[' income'])\n",
    "y = data[' income']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c018fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "282247ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Train the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d8f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Make predictions\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1446ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8707200982650084\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      4942\n",
      "           1       0.80      0.62      0.70      1571\n",
      "\n",
      "    accuracy                           0.87      6513\n",
      "   macro avg       0.84      0.78      0.81      6513\n",
      "weighted avg       0.87      0.87      0.86      6513\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4699  243]\n",
      " [ 599  972]]\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec6ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      " relationship      0.352323\n",
      " capital-gain      0.220413\n",
      " education-num     0.200869\n",
      "age                0.062858\n",
      " capital-loss      0.057275\n",
      " hours-per-week    0.037289\n",
      " marital-status    0.027620\n",
      " occupation        0.024423\n",
      " workclass         0.005937\n",
      " sex               0.003972\n",
      " fnlwgt            0.003460\n",
      " education         0.002113\n",
      " native-country    0.000971\n",
      " race              0.000476\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Optional: Feature Importance\n",
    "feature_importance = pd.Series(gbc.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7f1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa964e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665b92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7935b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass   fnlwgt   education   education-num  \\\n",
      "0   39          State-gov    77516   Bachelors              13   \n",
      "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
      "2   38            Private   215646     HS-grad               9   \n",
      "3   53            Private   234721        11th               7   \n",
      "4   28            Private   338409   Bachelors              13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "    capital-gain   capital-loss   hours-per-week  native-country  income  \n",
      "0           2174              0               40   United-States   <=50K  \n",
      "1              0              0               13   United-States   <=50K  \n",
      "2              0              0               40   United-States   <=50K  \n",
      "3              0              0               40   United-States   <=50K  \n",
      "4              0              0               40            Cuba   <=50K  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              32561 non-null  int64 \n",
      " 1    workclass       32561 non-null  object\n",
      " 2    fnlwgt          32561 non-null  int64 \n",
      " 3    education       32561 non-null  object\n",
      " 4    education-num   32561 non-null  int64 \n",
      " 5    marital-status  32561 non-null  object\n",
      " 6    occupation      32561 non-null  object\n",
      " 7    relationship    32561 non-null  object\n",
      " 8    race            32561 non-null  object\n",
      " 9    sex             32561 non-null  object\n",
      " 10   capital-gain    32561 non-null  int64 \n",
      " 11   capital-loss    32561 non-null  int64 \n",
      " 12   hours-per-week  32561 non-null  int64 \n",
      " 13   native-country  32561 non-null  object\n",
      " 14   income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "                age        fnlwgt   education-num   capital-gain  \\\n",
      "count  32561.000000  3.256100e+04    32561.000000   32561.000000   \n",
      "mean      38.581647  1.897784e+05       10.080679    1077.648844   \n",
      "std       13.640433  1.055500e+05        2.572720    7385.292085   \n",
      "min       17.000000  1.228500e+04        1.000000       0.000000   \n",
      "25%       28.000000  1.178270e+05        9.000000       0.000000   \n",
      "50%       37.000000  1.783560e+05       10.000000       0.000000   \n",
      "75%       48.000000  2.370510e+05       12.000000       0.000000   \n",
      "max       90.000000  1.484705e+06       16.000000   99999.000000   \n",
      "\n",
      "        capital-loss   hours-per-week  \n",
      "count   32561.000000     32561.000000  \n",
      "mean       87.303830        40.437456  \n",
      "std       402.960219        12.347429  \n",
      "min         0.000000         1.000000  \n",
      "25%         0.000000        40.000000  \n",
      "50%         0.000000        40.000000  \n",
      "75%         0.000000        45.000000  \n",
      "max      4356.000000        99.000000  \n",
      "Accuracy: 0.8707200982650084\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      4942\n",
      "           1       0.80      0.62      0.70      1571\n",
      "\n",
      "    accuracy                           0.87      6513\n",
      "   macro avg       0.84      0.78      0.81      6513\n",
      "weighted avg       0.87      0.87      0.86      6513\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4699  243]\n",
      " [ 599  972]]\n",
      "Feature Importances:\n",
      " relationship      0.352323\n",
      " capital-gain      0.220413\n",
      " education-num     0.200869\n",
      "age                0.062858\n",
      " capital-loss      0.057275\n",
      " hours-per-week    0.037289\n",
      " marital-status    0.027620\n",
      " occupation        0.024423\n",
      " workclass         0.005937\n",
      " sex               0.003972\n",
      " fnlwgt            0.003460\n",
      " education         0.002113\n",
      " native-country    0.000971\n",
      " race              0.000476\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 2: Load your dataset\n",
    "# Replace 'your_dataset.csv' with your file path\n",
    "data = pd.read_csv('income_evaluation.csv')\n",
    "\n",
    "# Step 3: Understand the data\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Step 4: Preprocess the data\n",
    "# Handle missing values if any\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert categorical variables to numeric (if any)\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Step 5: Define features and target\n",
    "# Replace 'target_column' with the name of your target column\n",
    "X = data.drop(columns=[' income'])\n",
    "y = data[' income']\n",
    "\n",
    "# Step 6: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature Importance\n",
    "feature_importance = pd.Series(gbc.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c574a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67457e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "977bd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sir cha code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aacfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant libraries\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#STEP-1: Import Libraries\n",
    "# Code to read csv file into colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "#STEP-2: Autheticate E-Mail ID\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "\n",
    "# Get File from Drive using file-ID\n",
    "downloaded = drive.CreateFile({'id':'1zI-X3zdiuM9u74zQyKIShvAUtPJQ7jUK'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('income_evaluation.csv')\n",
    "# https://drive.google.com/file/d/1zI-X3zdiuM9u74zQyKIShvAUtPJQ7jUK/view?usp=sharing  (Dataset Downloads Link)\n",
    "\n",
    "\n",
    "\n",
    "#Now let’s read the dataset and look at the columns to understand the information better.\n",
    "#https://drive.google.com/file/d/1zI-X3zdiuM9u74zQyKIShvAUtPJQ7jUK/view?usp=sharing\n",
    "df = pd.read_csv('income_evaluation.csv')\n",
    "df.head()\n",
    "\n",
    "df.shape\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "\n",
    "df.columns\n",
    "#df.drop(columns=' fnlwgt',inplace=True)\n",
    "df.columns\n",
    "\n",
    "X = df.drop(columns=' income')\n",
    "y = df[' income']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(a):\n",
    "    le = LabelEncoder()\n",
    "    df[a] = le.fit_transform(df[a])\n",
    "    \n",
    "    \n",
    "label_list = [' workclass', ' education',' marital-status',\n",
    "       ' occupation', ' relationship', ' race', ' sex',' native-country', ' income']\n",
    "\n",
    "\n",
    "for i in label_list:\n",
    "    label_encoder(i)\n",
    "    \n",
    "df.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([' income'],axis=1).values   # independant features\n",
    "y = df[' income'].values\t\t\t\t\t# dependant variable\n",
    "\n",
    "# Choose your test size to split between training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)\n",
    "print(\"X_test shape:\",X_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "\n",
    "#Buildimg Gradient Boosting Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "gradient_booster = GradientBoostingClassifier(learning_rate=0.1)\n",
    "accuracies = cross_val_score(gradient_booster, X_train, y_train, cv=5)\n",
    "gradient_booster.fit(X_train,y_train)\n",
    "\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",gradient_booster.score(X_test,y_test))\n",
    "\n",
    "\n",
    "result_dict_train = {}\n",
    "result_dict_test = {}\n",
    "result_dict_train[\"Gradient-Boost Default Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Gradient-Boost Default Test Score\"] = gradient_booster.score(X_test,y_test)\n",
    "\n",
    "\n",
    "grid = {\n",
    "    'learning_rate':[0.01,0.05,0.1],\n",
    "    'n_estimators':np.arange(100,500,100),\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "gb_cv = GridSearchCV(gb, grid, cv = 4)\n",
    "gb_cv.fit(X_train,y_train)\n",
    "print(\"Best Parameters:\",gb_cv.best_params_)\n",
    "print(\"Train Score:\",gb_cv.best_score_)\n",
    "print(\"Test Score:\",gb_cv.score(X_test,y_test))\n",
    "\n",
    "result_dict_train\n",
    "result_dict_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
